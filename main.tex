\documentclass[conference]{IEEEtran}

% UTF8 support
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}

\usepackage{paralist}

\usepackage[draft]{fixme}
\usepackage{todonotes}

\graphicspath{{figs/}}
\newcommand{\eg}{{\textit{e.g.~}}}
\newcommand{\etal}{{\textit{et al.~}}}
\newcommand{\ie}{{\textit{i.e.~}}}

\begin{document}

\title{Simulation and HRI: Recent Perspectives}

\author{\IEEEauthorblockN{
Séverin Lemaignan\IEEEauthorrefmark{2},
Marc Hanheide\IEEEauthorrefmark{7},
Michael Karg\IEEEauthorrefmark{4},
Harmish Khambhaita\IEEEauthorrefmark{1},
Lars Kunze\IEEEauthorrefmark{5},\\
Florian Lier\IEEEauthorrefmark{3},
Ingo Lütkebohle\IEEEauthorrefmark{6} and
Grégoire Milliez\IEEEauthorrefmark{1}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Computer-Human Interaction for Learning and Instruction, École Polytechnique Fédérale de Lausanne, Switzerland}
\IEEEauthorblockA{\IEEEauthorrefmark{7}Lincoln Centre for Autonomous Systems, University of Lincoln, Lincoln, United Kingdom}
\IEEEauthorblockA{\IEEEauthorrefmark{4}Institute for Advanced Study, Technische Universität München, Garching, Germany}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Laboratoire d'Analyse et d'Architecture des Système, Université de Toulouse, Toulouse, France}
\IEEEauthorblockA{\IEEEauthorrefmark{5}Intelligent Robotics Lab, School of Computer Science, University of Birmingham, United Kingdom}
\IEEEauthorblockA{\IEEEauthorrefmark{3}Cognitive Interaction Technology --- Center of Excellence, Bielefeld University, Bielefeld, Germany}
\IEEEauthorblockA{\IEEEauthorrefmark{6}Machine Learning and Robotics Lab, Institute for Parallel and Distributed Systems, Universität Stuttgart, Germany}
}}


\maketitle

\begin{abstract}

Simulation in robotics is often a love-hate relationship: while simulators do
save us a lot of time and effort compared to regular deployment of complex
software architectures on complex hardware, simulators are also known to evade
many (if not most) of the real issues that robots need to manage when they enter
the real world.  Because humans are the paragon of dynamic, unpredictable,
complex, real world entities, simulation of human-robot interactions may look
condemn to fail, or, in the best case, to be mostly useless.  This collective
article reports on five unrelated applications of the MORSE simulator in the
field of human-robot interaction: It appears that simulation is already useful,
if not essential, to successfully carry out research in the field of HRI, and
sometimes in scenarios we do not anticipate.

\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

Simulation of human-robot interaction is a challenge: it lies at the crossroad
of \emph{robotic simulation} (which brings in requirements like physical
accuracy, low latencies, high bandwidth, integration within complex software
architectures) and \emph{embodied virtual agents} (which also brings in its own
requirements like realistic human kinematics and visual rendering, complex
behaviours, rich user interface), while still remaining a \emph{tool}: in order
\emph{not} to stand in the way of our day to day development workflow, it must
\emph{feel} lightweight, responsive, easy to setup and deploy.

This paper presents how the Modular OpenRobots Simulation Engine (MORSE,
figure~\ref{fig|morse-hri})~\cite{morse_simpar_2012} simulator attempts to
address this challenge to eventually provide a convenient support for research
in human-robot interaction.  We first give a brief overview of the simulator
with a focus on HRI-specific features, and then report on several real-world
applications. These five case-studies illustrate the collective nature of this
article: we report on contributions and experiences in human-robot interaction
simulation from five unrelated projects, conducted by different people in
different universities and research institutes, only sharing the MORSE simulator
as common simulation platform. The sections~\ref{sc:assessment} to~\ref{sc:ci}
present each of these projects, and try to highlight both the positive
outcomes of deploying simulation environments for HRI, and the pitfalls and more
fundamental issues that simulation of human-robot interaction still faces.

\subsection*{HRI and simulation}

\begin{figure}[ht!]
      \centering 
      \includegraphics[width=0.9\linewidth]{morse_pr2.jpg}
      \caption{A PR2 and a human avatar in MORSE.}
      \label{fig|morse-hri}
\end{figure}

When we mention simulators in the following, we refer to simulation engines with
support for physically simulating both robot kinematics and dynamics, as well as
physical objects in the environment, and where the control and sensor interface
is close to or the same as it would be on real robots. In this paper, we beside
only consider engines which support rendering and animation of human agents
suitable for HRI, and which have been actually used in this context (while many
engines could theoretically support this use case, few of them have actually
demonstrated it). For the interested reader, a broader overview of research in
robotic simulation is provided in~\cite{Ando2010}.

Beside MORSE, simulators with explicit support for controlling a human agent
include USARSim (Lewis~\etal\cite{lewis2007usarsim}), which is commonly used in
the field of rescue robotics, and used in dozens of HRI studies, and, to a
lesser extend, experiments with character animation have been developed in the
widely-used simulator Gazebo (Koenig and Howard~\cite{Koenig2004}).


%Note, however, that USARSim and MORSE are quite similar technically, in that
%both are based on an underlying game engine (the Unreal Tournament Development
%
%respectively), which has been extended with robot actuator and sensor models,
%and both support control through common middlewares. We prefer MORSE for its
%fully open source approach, and some other technical differences (see next
%section for more details), but we believe that due to the overwhelming
%similarities most, if not all, requirements and/or conclusions identified would
%also apply to work using USARSim.

All of these simulators are based around game engines (the Blender Game Engine,
Unreal Tournament Development Kit and Ogre3D, respectively). While their
built-in support for human models varies, all of these engines require the
developer to specify the agents' behavior in detail. In practice, this limits
human agent behaviors to relatively simple motions and interactions, and perhaps
not surprisingly, most HRI simulations so far are carried out in
\emph{tele-operation} settings, where only the robot and the environment, but
not the human agent, are actually simulated.

In contrast, current work on embodied virtual agents (EVA) usually provides 
higher-level functionality, such as simulated emotion dynamics, behavior 
generation based on action primitives, conversational dialogue systems, and
up to cognitive simulations. However, integrating these into a coherent 
system with an acceptable interface remains 
challenging~\cite{gratch2002creating}. We do not think that general-purpose
simulators will acquire any of these functions soon, but they could be
capable of integrating external components that do, for example, by offering 
an interface for the Behavior Markup Language~\cite{kopp2006towards} popular
in the EVA community, or by exposing a (lower-level) 
H-Anim\footnote{\url{http://www.h-anim.org/}} interface. H-Anim is already
supported by Blender, MORSE's foundation.

That said, the use cases shown in the next sections hopefully demonstrate that
even with current limited functionalities, many relevant scenarios can already
be realized.


\subsection*{HRI and the MORSE simulator}

The five projects that are presented in this article all rely on the MORSE as
simulation platform. We briefly go over the main MORSE features in this section,
and kindly suggest the interested readers to refer to~\cite{morse_simpar_2012}
or to the MORSE website\footnote{\url{http://morse-simulator.github.io}} for
details.

MORSE is a open-source tool developed for academic robotic research with
contributions from over 15 institutions worldwide. It is a domain independent
simulator where virtual robots can interact with a 3D environment, using sensors
and actuators that behave in the same way as their counterparts in the real
world. MORSE relies on the Blender \emph{Game Engine}, a real-time 3D runtime
integrated to the open-source Blender modeling toolkit, both for advanced 3D
(OpenGL shaders) and physics simulation (based on the {\sc Bullet} physics
engine\footnote{\url{http://www.bulletphysics.org}}). This allows for semi-realistic simulation of complex environments.
The MORSE components (sensors and actuators) exchange data with the robotics
software via middleware bindings (\emph{Software In The Loop} architecture).
Four robotic middlewares are currently supported, including ROS and YARP, as
well as a generic socket-based protocol. This design aims at providing a
seamless experience when switching back and forth between the simulator and the
real robot. As expected for a versatile robotic simulator, a set of standard
robotic platforms, actuators and sensors (more than 50 components) is
provided and enables fast creation of simulation scenarios, while custom
components can be added via Python (for the behaviours) and Blender (for the 3D
design).

Two MORSE features stand out. First, MORSE has been primarily designed with a
command-line interface, and only features a minimal (and fully optional)
graphical user interface. This makes MORSE mainly targeted to an academic
audience, where efficiency and lightness prevail.  Simulation scenes are
actually short Python programs, thus well suited for sharing and versioning.
This also eases the integration of the simulator into larger development
workflows, and MORSE is successfully integrated into several continuous
integration systems (Travis, Jenkins).

Second, MORSE has a concept of \emph{abstraction levels}: sensors and actuators
may expose several levels of abstraction, corresponding to different level of
realism. For instance, users may choose if the odometry sensor returns only a
curvilinear distance, a $dX, dY, dZ$ differential vector, or the absolute
position of the robot (integrated odometry). This allows users that are testing
low-level components to do so, while users working at a higher abstraction
levels (typically in HRI) do not have to run full robotic software stacks (and
thus, benefit from a lighter environment), and can work in a more deterministic
environment. This feature can be finely controlled, on a per-component basis.

For HRI applications, MORSE provides a human avatar that can be fully controlled
(displacement, gaze, grasping of objects, interactions with the environment like
turning lights on, opening drawers, doors...) in a first-person-shooter style.
This enables the researcher to quickly setup and test human-robot interactions
with a tele-operated human model, hence with realistic human behaviours. As
presented in~\cite{lemaignan2012morse}, the human avatar can be controlled from
a Kinect-like device.  The same avatar can also be programmatically controlled
by external scripts, as any robot in MORSE. With standard MORSE actuators like
the \emph{waypoint} actuator, the researcher can for instance pre-define paths
that the human avatar will follow in a simulated environment.



\section{HRI Simulation : Five Scenarios}

To illustrate how simulation can support research in HRI, we present in the next
sections five case-studies.  The first three scenarios, \emph{Situation
Assessment for HRI and Simulated Feedback}, \emph{An Expectations Framework for
Domestic Robot Assistants} and \emph{Preliminary Testing of Human-Aware
Navigation Planner} illustrate the typically use-case for simulation: rather
complex virtual environments are created where the human presence plays a
central role, and HRI algorithms are tested in a convenient and repeatable way.
The fourth scenario, \emph{Data Acquisition through Automatic Scene Generation}
shows how simulation is used as an alternate source of input to train robots to
behave in human environments, and the last scenario, \emph{Automated Execution
of Prototype HRI Experiments}, presents how the simulator can be used to provide
automatic testing of human-aware behaviours, fully integrated to the software
development workflow. Each of the presentations follow the same structure: we
first introduce the scenario, we then higlight how simulation has been leveraged
and its benefits, and we finally mention some of the shortcomings of the tool.

\subsection{Situation Assessment for HRI and Simulated Feedback}
\label{sc:assessment}

When studying human-robot interaction, understanding the environment in which
agents will interact is a key issue. In this first application, MORSE provides a
virtual environment that we use to harness situation assessment algorithms
(performed by a software called SPARK ~\cite{Warnier2012a}, for SPAtial Reasoning and Knowledge) that
also include human-centered \emph{perspective taking}. The robot updates its
knowledge in SPARK using its own position, human position and objects seen
through abstracted, symbolic cameras provided by MORSE (so-called
\emph{semantic} cameras). In this particular scenario (figure~\ref{fig|spark}),
the human is sitting in a couch and ask the robot to bring specific objects that
may be in another room.

\begin{figure}[H]
      \centering
      \includegraphics[width=\linewidth]{morsespark.png}
      \caption{On the left side, the MORSE environment ; on the right side, the same
      environment, as perceived by the robot in the SPARK situation assessment
      module.}
      \label{fig|spark}
\end{figure}

\emph{Benefits of the simulation} The direct benefits of relying on MORSE for
the development of the situation assessment algorithms is the low-cost of
deployment (manual testing on physical systems is labour-intensive), as well as
the repeatability of the experimental conditions, important to assess the
algorithmic improvements.  Also, relying on MORSE effectively supports
collaboration between the partners involved in this project (MaRDi
project\footnote{\url{http://mardi.metz.supelec.fr}}): our partners are also
using MORSE simulation to test their software and collect data with the same
environment in their laboratory, where they focus on dialog processing. They can
train their dialog system using MORSE feedback to test the robot behaviours.

\emph{Specific limitations} MORSE currently only partially supports features
related to sound management (no simulation of microphones, no support for sound
propagation models), thus only providing an incomplete model of the environment.

\subsection{An Expectations Framework for Domestic Robot Assistants}
\label{sc:expectations}

In this scenario, an apartment is simulated in which a domestic 
service robot is living together with a person (figure~\ref{fig|apartment}). 
A PR2 robot is controlled via ROS and the {\sc Cram} reactive plan language, 
which is used on several other real robots~\cite{pancakes11humanoids}. The robots' 
duty is to observe the person performing different activities and detect unexpected 
situations based on the validation of different types of expectations~\cite{Karg2013}. 
The detection of such unexpected behavior can help future domestic service robots 
to better assess situations and adapt their actions to human behavior.

\emph{Benefits of the simulation} The use of the MORSE simulator enabled us to set up a large, 
testbed by combining realistic robot control via the ROS middleware with the
unpredictability of human behavior using the human component of MORSE. Setting
up of such an apartment in a real-world setting, together with a suitable
sensor setup and a reliable robot control, would not only introduce huge costs
but would also be a time-consuming task which can distract researchers from
their actual research focus. The use of the simulated scenario enables us to
gain many insights into the problem domain in a scenario that would not been
possible within our project and ultimately led to the successful validation of
the approach in a spatially limited real-world scenario.

\begin{figure}[H]
      \centering
      \includegraphics[width=\linewidth]{morse_apartment.png}
      \caption{A simulated apartment with a domestic service robot and a person.}
      \label{fig|apartment}
\end{figure}

The human component of MORSE enabled us to test and validate our approach
dynamically in a variety of situations. Since it can be controlled in real-time
like in a 3D computer game while at the same time, a robot can be simulated by
state-of-the-art components, it is possible to generate a multitude of
situations on which the robot has to react. This greatly supported our project
to gain insights about our approach, detect weak points and make improvements.

\emph{Specific limitations} While the game-like control of the human avatar 
successfully enabled us to simulate simple actions like picking and placing objects, 
opening doors and using light switches, actions that require find-grained control 
of the arms and hands are not yet possible. For instance, when trying to set a table for 
diner, it is often not possible to accurately place objects like cutlery. Also, the human
avatar is currently restricted to using one arm which is unrealistic in activities 
like table setting, where humans often use both arms for pick and place actions.
 

\subsection{Preliminary Testing of Human-Aware Navigation Planner}
\label{sc:navigation}

To evaluate the improvements in the human-aware navigation planner developed at
LAAS we carried out a user study. For the user study an experiment was set up,
where a robot encounters a human crossing its path (at $90^{\circ }$ angle to
each other) while the robot is moving forward to its navigation goal. For
preliminary testing of the planning algorithm, our lab areas was simulated in
MORSE (figure ~\ref{fig|hanp}). This simulated environment was extensively used
to review the algorithm before it was deployed on the PR2 robot to carry out
real-world experiments (whose results have been published
in~\cite{ThibaultKruse2014}).

\begin{figure}[H]
      \centering
      \includegraphics[width=\linewidth]{morsehanp.png}
      \caption{Test of human-aware navigation within MORSE}
      \label{fig|hanp}
\end{figure}

\emph{Benefits of the simulation} Development of human-robot interaction
algorithms often require iterative process of prototyping, testing and
reviewing. Setting up and experiment and testing of robot navigation algorithms
especially for large environments involving humans is time consuming and is
subject to availability of lab resources while working in a shared lab between
different groups of researchers. Full support of the PR2 robot model among
others, availability of a human model, and a convenient way of setting up
experiment environment using Blender software were the most prominent features
for choosing MORSE as the simulation environment for these experiments. Since
MORSE already provides ROS bindings for the PR2 robot and human pose it requires
minimal effort to switch between real-world and simulated environments.

As a consortium member in the EU project
SPENCER\footnote{\url{http://www.spencer.eu}}, we plan to develop novel
algorithms for robot navigation in large populated environments, \eg airports.
In the future we plan to use MORSE to simulate such large environment with
multiple human models. This will certainly push the limits of simulation for HRI
and hopefully provide new benchmark for MORSE.

\emph{Specific limitations} All DoFs of the human posture in MORSE already have an
interface support for the {\sc pocolibs} and YARP middlewares. It would be a valuable
addition to MORSE to add a ROS interface for the same, and publish all these
DoFs as coordinate frames using the typical {\tt tf} package. Moreover, an easier
way to attach camera to the human eyes would be appreciated. For HRI experiments
this will give a human perspective on the robot actions and its effects on the
environment.


\subsection{Data Acquisition through Automatic Scene Generation}
\label{sc:generation}

Autonomous mobile robots that are to help and assist people in care homes,
households, and at other workplaces have to understand how human activities
affect the dynamics of objects in the environment. That is, robots need to know,
when, where and how people manipulate objects and how they arrange and structure
them in space. In the context of the STRANDS
project\footnote{\url{http://www.strands-project.eu}} we aim for robots that
understand the long-term, spatio-temporal relationships of objects and
activities of people. In the scenario described in this paper, we looked in
particular at learning qualitative spatial relations of objects on office desks.
As an accurate classification and pose estimation of objects on real-world
office desks is still a challenging and difficult task for current robot
perception systems we acquired a data set of object arrangements using the MORSE
simulator. For this, we first bootstrapped an object statistics from manually
labeled images of real office desks, and secondly, automatically generated a set
of physically possible desktop scenes
(figure~\ref{fig:simulated-desktop-scenes}). Based on the generated data we
learned relational models of object arrangements on desks. The learnt models
enabled a robot to predict the position of an object given a landmark. We
employed these models to effectively guide a simulated and a real robot in
object search tasks and evaluated its performance~\cite{kunze14indirect}.

\emph{Benefits of the simulation} First, the automatic scene generation (made
easy by the use of Python to ``program'' the simulation scenes) and annotation
of object arrangements in simulation is useful for the acquisition of large
amounts of data over short periods of time. The generated data enabled us to
design, implement and to evaluate our methods for predicting object locations
before having a real-world data set in place. Secondly, the generation of object
arrangements can increase the variability of scenes in human-robot experiments
in general. Given the dynamics of objects in the real world it is important not
to oversimplify human-robot experiments in simulated environments but make them
as realistic as possible (in a controlled way). Finally, in future work, we plan
to use the generated desktop scenes in web-applications to crowdsource Natural
Language descriptions of object arrangements and commands for robots from
Internet users.

\emph{Specific limitations} The default installation of MORSE already includes a
fair set of pre-modeled objects. However, these objects are spread over
different environments and lack a coherent definition with respect to their
reference frame, bounding box, and/or scale. A desirable feature would be that
objects are kept in a global or some domain specific object databases and that
they are modeled in a consistent way. This would ease the usage of different
types of objects and thereby allow users and researchers to focus on their
goals. Also the addition and/or removal of objects at run-time would be a nice
feature as a running MORSE instance could be used more flexible, for example,
as a robot's belief state.

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\columnwidth]{figs/scenes.png}
  \caption{Automatically generated scenes of office desks.}
  \label{fig:simulated-desktop-scenes}
\end{figure}


\subsection{Automated Execution of Prototype HRI Experiments}
\label{sc:ci}

In human-robot interaction studies, robots often indicate behavioral variability
that may influence the experiment's final outcome.  However, manual testing on
physical systems is usually the only way to prevent this, but remains
labour-intensive. To tackle this issue, we introduced \emph{early automated
prototype testing}~\cite{2645922} that consists of: a simulation environment, a
software framework for automated bootstrapping of prototype systems, execution
verification of system components, automated result assessment of experiments
and a Continuous Integration (CI) server to centralize experiment execution. In
our setup we bootstrap and execute a simulated prototype system on a CI server
and assess the results in each run. In this particular scenario, a robot must
report the location of a virtual human in a domestic environment. Both the
robot and the human are moving in the scene and meet in front of a table
(figure~\ref{fig|proto}).

\begin{figure}[H]
      \centering
      \includegraphics[width=0.9\linewidth]{proto-setup.png}
      \caption{Prototype HRI Simulation.}
      \label{fig|proto}
\end{figure}

The goal of this simulation setup is to incrementally decrease the level of
abstraction until a satisfactory/sufficient degree of ``realism'' to make an
assumption about real world behavior, is reached --- in an integrated and
continuous approach. In order to achieve this goal, we make use of two essential
MORSE features: \textit{a)} the human avatar that can be steered (set waypoints)
interactively via middleware and \textit{b)} a \emph{semantic} camera that
extracts the location of a specific entity in the simulation environment.  The
semantic camera is attached to the robot. If the human enters the robot's field
of view, the location is reported and sent via middleware. After each CI run,
the recorded movement trajectory of the human avatar is assessed (plotted) and
archived. We have explicitly chosen to simplify the extraction of the location
of the human to acquire a ground truth in the first iterations of the
simulation. Based on the ground truth, we are able to exchange diverse
components, \ie the semantic camera with a simulated laser scanner to build a
person hypothesis for instance, thus gradually develop, assess and implement
more complex scenarios. 

\emph{Benefits of the simulation} First of all, the interactive (remotely
controllable) human avatar is useful to include a dynamic, yet not too
realistic, human component in this setup, which currently is a rare feature in
the world of simulators. Secondly, the level of abstraction of different
sensors, \ie semantic camera versus virtual laser scanner enables us to
gradually raise the level of complexity/realism and test different algorithms
based on abstract and almost realistic sensor inputs.  Lastly, the chance to
deploy MORSE in a Continuous Integration environment, \ie automatically run
simulation scripts, generates an additional benefit.
 
\emph{Specific limitations} To be even more useful, simulators and thus MORSE, must
feature a realistic ``walking cycle'' for human components. This is especially
important if laser scans are used to build a person hypothesis. Additionally, the
human avatar should feature (remotely) triggered ``actions'', \eg grasping a 
predefined object, sit down on a chair/sofa or open a door. Lastly, audio support, 
\ie Text-to-Speech output for the human component would significantly increase
the usability to assess algorithms which rely on multimodal inputs.  

\section{Discussion: A Place for Simulation in HRI?}

As a preliminary remark, we'd like to briefly discuss the \emph{cost} of
integrating MORSE into the scenarios we have presented so far. While estimating
the global cost of deploying a simulator is difficult (it can not be measured
only in quantitative ways), we have collected for each of the use-cases a simple
metric: the count of simulator-related lines of code ({\sc LoC}) required to
integrate MORSE into the project. This count appears to remain between 100 and
300 {\sc LoC} for each scenario: 263 {\sc LoC} for~\ref{sc:assessment}, 179
for~\ref{sc:expectations}, 115 for~\ref{sc:navigation}, 136
for~\ref{sc:generation}, and 229 for~\ref{sc:ci}.  This count includes Python
code and the shell scripts and launch files created to deploy the scenarios in
MORSE. These numbers give some hints regarding the integration effort, which
appear to be low for these use-cases.

Generally speaking, we believe, as researchers in HRI,  that simulation holds a
rightful place, both as an efficient engineering support tool, and as a novel
source of realistic yet repeatable (hence comparable) human inputs for our
systems. As such, the five scenarios that are presented here cover a range of
use-cases.  Using a simulator to provide a reference environment with repeatable
conditions (as in scenarios~\ref{sc:assessment}, \ref{sc:expectations} and
\ref{sc:navigation}) is the expected role of a robotic simulator. Here, MORSE
simply provides additional tools to represent and control humans, either in
perfectly repeatable ways (by pre-programming the human behaviour) or in less
repeatable but also more realistic ways (in the ``first-person shooter'' mode).
In these scenarios, simulation also appears useful to test a variety of
different (controlled) conditions in rather complex environments, and makes it
tractable even for individual PhD students. This would be hardly doable on a
daily basis if it was to be conducted on real robots.  Also mentioned, the
simulator plays an important role in several international projects, where it is
often the only way to share a common experimental setting.

Other, less obvious, use-cases for HRI simulation are also reported. The
``programmability'' of the simulator makes it a convenient tool for data
synthesis and acquisition in dynamic human environments
(scenario~\ref{sc:generation}), the concept of \emph{abstraction levels} can be
used to iteratively refine the algorithms, getting closer and closer to the
actual sensors outputs (scenario~\ref{sc:ci}), and finally, automated testing of
human-aware robotic softwares as presented in scenario~\ref{sc:ci} opens
interesting perspectives to improve development workflows in HRI.

These diverse use-cases support the idea that simulation is not only actually
useful as a support tool for development of human-robot applications, but also
\emph{enables} new research techniques in HRI. \emph{Continuous Integration}
illustrates this point: while HRI experiments are considered as notoriously
difficult to deploy, test and repeat, we show here how a simulator may enable
automated testing of more and more complex scenarios, including long-term
interaction.

Several issues are also raised. In its current state, the MORSE simulator
provides only an incomplete model of the environment. Sounds/speech models are
missing, and the ability to dynamically alter the simulated scene (in reaction
to particular events, for instance) is also perceived as something important.
Similarly, the human model(s) does not yet provide good enough accuracy, both at
the level of the user interface (some actions can not be done with the
interactive avatar), and at the simulation level (poor/missing walking cycles
for instance). Finally, the overall convenience of MORSE for HRI could be
improved, for instance by providing more assets (furnitures, objects,...)
related to human environments.  These issues, that are mostly technical and
could be addressed at the software level, show that simulators dedicated to HRI
application still need to mature.  In that regard, the next section presents
some of the directions that are currently researched.

\paragraph*{The next steps}

Several noteworthy developments related to HRI are currently shaping up in the
MORSE community. We outline below some of them, that suggest new applications we
believe relevant to HRI research.

A first line of investigation relates to the procedural generation of a variety
of realistic human models. {\sc MakeHuman} is such an open-source tool that
generates anatomically, kinetically and visually realistic human models
(figure~\ref{fig:makehuman}). This software has a tight integration with Blender,
and MORSE is soon to provide as well seamless integration with {\sc MakeHuman}
models. This will bring a wide range of characters to feed the simulations,
and extend testing environments with gender/size/age/skin color variances.  For
this feature to reach its full potential, {\sc MakeHuman} should however be
extended to support programmatic generation of models, since the graphical user
interface is currently required.

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\columnwidth]{figs/makehuman.png}
  \caption{Procedural generation of human models with {\sc MakeHuman}.}
  \label{fig:makehuman}
\end{figure}

Besides being able to control a human avatar in simulation programmatically and
deterministically, the possibility to automatically generate believable and
realistic crowd behaviours is being explored. In this context, the objective is
to adopt in MORSE technologies previously developed for computer games to generate
trajectories that control the MORSE avatars.  Based on the idea of \emph{social
forces}~\cite{helbing2001}, the work of~\cite{Szymanezyk2012crowd} is to be
adapted to provide believable and realistic movement of several humans within
MORSE. The approach is based on a grid-based representation that computes forces
for individual agents by combining information from other agents (\eg social
distances and group forming), from the environment (\eg obstacle avoidance) and
from a pre-defined set of individual goals, defined for each agent. The
resulting velocity vector for each agent can be directly interfaced with several
instances of MORSE avatar to generate natural movement trajectories. This
implementation can provide a more realistic and dynamic environment to study
human-robot spatial interaction and to provide a testbed for human-aware motion
planning, to give two exemplary use cases.

Another line of investigation looks at \emph{embedding} the researcher into the
robotic simulation. The purpose of such efforts is to provide a life-like
immersive simulation environment that would allow at the same time ecologically
valid human behaviours and repeatable, lightweight interaction settings.
In~\cite{lemaignan2012morse}, we presented how a human agent could interact with
a virtual robot through a deictic interface based on a Kinect. While arm
movements and small displacement (in a 2-3m\textsuperscript{2} zone) could be
fairly accurately transposed from the physical world to the simulation, the
overall interaction was not yet immersive (no head tracking, limited,
non-dynamic field of view on a TV screen, no sound). Two distinct projects are
currently looking into extending this line of research, one (at Bielefield
University) aiming at integrating emerging Virtual Reality devices (like Occulus
Rift) with MORSE, the other one (MarDI project) developing a virtual reality
cave, that include 360° projections and spatialized sound.

Also often suggested, the \emph{on-line} deployment of HRI simulations could
efficiently support large scale HRI studies. The simulator and specific
interaction scenarios would be embedded in a dedicated webpage and users would
control a human avatar from their webbrowsers. This would potentially enable
collection of large behavioural datasets. While MORSE development in that
direction has yet to start, it can be noted that the Gazebo simulator already
features a limited WebGL client, that act as a proof-of-concept.

Faster-than-realtime simulation, a recent feature of MORSE (currently at testing
stage), is a last development that can have significant applications for
HRI\fixme{finish that}

\paragraph*{To conclude}

These examples and ideas hopefully give a picture of the lively landscape of the
``Simulation for HRI'' community, that has built itself around the MORSE
simulator.  In the introduction, we mentioned how simulation in HRI had to
address in parallel constraints stemming from \emph{robotic simulation} and
\emph{virtual agent simulation}, while remaining a lightweight, easy-to-use
tool. We are certainly not yet there, much remains to be imagined, refined and
achieved.  Yet MORSE is already deployed in several institutions as a platform
that efficiently supports research in human-robot interaction. As an open-source
project, we strive for new use-cases and ideas, and warmly welcome researchers
that would like to join the effort.


%\section*{Acknowledgment}
%TODO

\bibliographystyle{abbrv}
\bibliography{main}

\end{document}
