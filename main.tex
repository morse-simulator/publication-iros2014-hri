%
%  == Collective paper on MORSE for HRI ==
%
%
% Editing of the article moves to GIT (Sharelatex does not expose the change history unless you
% pay for it, so it's difficult to track changes and merge them with GIT).
%
% The repo is here:  https://github.com/morse-simulator/publication-iros2014-hri
%
%
% The idea is: each of you present (in one section) its project, 
% putting an emphasis on:
%   1- why simulation is useful/needed for your use-case
%   2- is it satisfactory or not
%   3- what is good and could be useful to other researcher
%   4- what is missing both at the technical level (things that could be added 
%      to MORSE) and at a more fundamental level (things where simulation do 
%      not fit)
%
% It would be great to have one nice screenshot per project.
%
% Then, Severin and Florian write a synthesis in the conclusion.
%
% Severin will also write a short introduction + presentation of MORSE for HRI
%


\documentclass[conference]{IEEEtran}

% UTF8 support
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}

\usepackage[draft]{fixme}

\graphicspath{{figs/}}
\newcommand{\eg}{{\textit{e.g.~}}}
\newcommand{\etal}{{\textit{et al.~}}}
\newcommand{\ie}{{\textit{i.e.~}}}

\begin{document}

\title{Simulation and HRI: Recent Perspectives}
% I suggest for now to keep the authors in alphabetic order.
% Please add yourself!

\author{\IEEEauthorblockN{
Michael Karg\IEEEauthorrefmark{4},
Harmish Khambhaita\IEEEauthorrefmark{1},
Lars Kunze\IEEEauthorrefmark{5},
Séverin Lemaignan\IEEEauthorrefmark{2},
Florian Lier\IEEEauthorrefmark{3},
Ingo Lütkebohle\IEEEauthorrefmark{4} and
Grégoire Milliez\IEEEauthorrefmark{1}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Laboratoire d'Analyse et d'Architecture des Système,
Université de Toulouse,
Toulouse, France}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Computer-Human Interaction for Learning and Instruction,
École Polytechnique Fédérale de Lausanne,
Lausanne, Switzerland}
\IEEEauthorblockA{\IEEEauthorrefmark{3}Cognitve Interaction Technology --- Center of Excellence,
Bielefeld University, Bielefeld, Germany}
\IEEEauthorblockA{\IEEEauthorrefmark{4}Institute for Advanced Study, Technische Universit\"{a}t M\"{u}nchen, D-85748 Garching, Germany}
\IEEEauthorblockA{\IEEEauthorrefmark{5}Intelligent Robotics Lab, School of Computer Science, University of Birmingham, United Kingdom}
}}


\maketitle

\begin{abstract}

Simulation in robotics is often a love-hate relationship: while simulators do
save us a lot of time and effort compared to regular deployment of complex
software architectures on complex hardware, simulators are also known to evade
many (if not most) of the very real issues that robots need to manage when they
enter the real world.  Because humans are the paragon of dynamic, unpredictable,
complex, real world entities, simulation of human-robot interactions may look
condemn to fail, or, in the best case, to be mostly useless.  This collective
article reports on five unrelated and actually different applications of the
MORSE simulator related to human-robot interaction: It appears that simulation
is already useful (and even essential in some case) to successfully carry out
research in the field of HRI, be it for not-so-expected reasons.

\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

% We should def. list a few requirements here, based on our experience



This article attempts to provide feedback from field experiences with simulation
for human-robot interaction. The originality of this contribution lies into its
collective nature: we report here contributions and experiences from five
unrelated projects, conducted by different people in different universities and
research institutes, only sharing the MORSE simulator as common simulation
platform.

The sections~\ref{scenario1} to~\ref{scenario5} present each of these projects,
and try to shed some light on the positive outcomes of deploying simulation
environments for HRI, as well as the pitfalls and more fundamental issues that
simulation of human-robot interaction still faces.

\subsection*{HRI and simulation}

\begin{figure}[ht!]
      \centering
      \includegraphics[width=0.9\linewidth]{morse_pr2.jpg}
      \caption{A PR2 and a human avatar in MORSE.}
      \label{fig|morse-hri}
\end{figure}



Simulation in robotics often focuses on simulation of either low-level physical
properties (physics simulation, kinematics, perception with fake cameras, laser
scanners, etc.) or macroscopic behaviours (in particular, collective
behaviours). Simulators like Gazebo, VRep, Webots, OpenGrasp \fixme{add refs}
primarly belong to the first category, while tools like Stage \fixme{other
ones...} are used with multi-robot interaction.

However, simulation is seldom applied to human-robot interaction contexts, and
only few publications report on successful deployments of simulators for HRI.
We can mention Lewis~\etal\cite{lewis2007usarsim}, who present how they relied
on {\sc USARSim} to carry on HRI experiments, but only focused on
teleoperation: it did not involve robots having to interact itself with another
human.  Hirth~\etal\cite{hirth2013development} used simulation to design and
implement a shared human-robot task (based on tangram solving). They note that
simulation enables reproducible experimental conditions which are traditionally
difficult to enforce in HRI.

Chernova~\etal\cite{Chernova2011} propose a different yet related perspective:
they deploy an on-line game where two \emph{humans} play together, one being a
human in the game, while the other one plays a robot. They record the resulting
interaction to crowd-source natural human-robot interactions. This is no
\textit{per-se} robotic simulation (no robot software is involved in the game),
but suggest an interesting application of simulated \emph{on-line} HRI.

\fixme{anything else?? there must be...!}

% Also mention the focus of simulation so far: Physics, Kinematics, Actuator simulation a human component
% has been neglected to far See also Comment below for related work [flier] -->

% Mention Gazebo "animated characters": http://gazebosim.org/wiki/Tutorials/intermediate/animated_characters 

To our best knowledge, no robotic simulation package provide explicit support
for human-robot interaction, and this is what is currently being built into the
open-source MORSE project.

\subsection*{HRI and the MORSE simulator}

The five projects that are presented in this article all rely on the Modular
OpenRobots Simulation Engine (MORSE)~\cite{Echeverria2011, morse_simpar_2012} as
simulation platform (figure~\ref{fig|morse-hri}). We briefly recap the main
MORSE features in this section, and kindly suggest the interested readers to
refer to the aforementioned references or to the MORSE
website\footnote{\url{http://morse-simulator.github.io}} for details.

MORSE is a open-source tool developed for academic robotic research with
contributions from over 15 institutions worldwide. It is a domain independent
simulator, where virtual robots can interact with a 3D environment, using
sensors and actuators that behave in the same way as their counterparts in the
real world.

MORSE relies on the Blender \emph{Game Engine}, a real-time 3D runtime
integrated to the open-source Blender modeling toolkit, for advanced 3D (OpenGL
shaders) and physics simulation ({\sc Bullet} physics engine). This allows for
semi-realistic simulation of complex environments.

The MORSE components (sensors and actuators) exchange data with the robotics
software via middleware bindings (\emph{Software In The Loop} architecture).
Four robotic middlewares are currently supported, including ROS and YARP, as
well as a generic socket-based protocol. This design aims at providing a
seamless experience when switching back and forth between the simulator and the
real robot. As expected for a versatile robotic simulator, a set of standard
robotic platforms, actuators and sensors (more than 50 so-called components) is
provided and enables fast creation of simulation scenarii, while custom
components can be added via Blender (for the 3D design) and Python (for the
behaviours).

Two MORSE features stand out. First, MORSE has been primarily designed to be
used in a command-line environment, and only features a minimal (and fully
optional) graphical user interface. This makes MORSE mainly targeted to an
academic audience, where efficiency and lightness prevail. For instance,
simulation scenes are actually short Python programs, well suited for sharing
and versioning. This also eases the integration of the simulator into larger
development workflows, and MORSE has been, for instance,  successfully
integrated into several continuous integration systems (Travis, Jenkins).

Second, MORSE has a concept of \emph{realism level}: sensors and actuators may
expose several levels of abstraction, corresponding to different level of
physical accuracy. For instance, users may choose if the odometry sensor returns
only a curvilinear distance, a $dX, dY, dZ$ differential vector, or the absolute
position of the robot (integrated odometry). This allows users that are testing
low-level components to do so, while users working at a higher abstraction level
do not have to run a full robotic software stack to get the position of the
robot.

MORSE also provides several features focused on human-robot
interaction~\cite{lemaignan2012morse} [...]

\section{Scenarios}
% Explain this section and introduce all use-cases

Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula
eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient
montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque
eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo,
fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut,
imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium.
Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate
eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac,
enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus
viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam
ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui.
Etiam rhoncus. Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper
libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel,
luctus pulvinar, hendrerit id, lorem. Maecenas nec odio et ante tincidunt
tempus. Donec vitae sapien ut libero venenatis faucibus. Nullam quis ante. 

\subsection{Automated Execution of Prototype HRI Experiments}
\label{scenario1}

\emph{Use-Case:} In Human-Robot Interaction studies, robots often indicate
behavioral variability that may influence the experiment's final outcome.
However, manual testing on physical systems is usually the only way to prevent
this, but remains labour-intensive. To tackle this issue, we introduced
\emph{early automated prototype testing} \cite{2645922} that consists of: a
simulation environment, a software framework for automated bootstrapping of
prototype systems, execution verification of system components, automated result
assessment of experiments \cite{2563606} and a Continuous Integration (CI)
\cite{duvall2007continuous} server to centralize experiment execution. In our
setup we bootstrap and execute a simulated prototype system on a CI server and
assess the results in each run. In this particular scenario, a robot must report
the location of a virtual human in a domestic environment. Both, the robot and
the human, are moving about in the scene and meet in front of a table
(Figure~\ref{fig|proto}).

\begin{figure}[H]
      \centering
      \includegraphics[width=0.9\linewidth]{proto-setup.png}
      \caption{Prototype HRI Simulation.}
      \label{fig|proto}
\end{figure}

The goal of this simulation setup is to incrementally decrease the level of
abstraction until a satisfactory/sufficient degree of ``realism'', to make an
assumption about real world behavior, is reached --- in an integrated and
continuous approach. In order to realise this goal, we make use of two essential
MORSE features: a) the human avatar that can be steered (set waypoints)
interactively via middleware and b) a semantic camera
\footnote{\url{openrobots.org/morse/doc/stable/user/sensors/semantic_camera.html}}
that extracts the location of a specific entity in the simulation environment.
The semantic camera is attached to the robot. If the human enters the robot's
field of view, the location is reported and sent via middleware. After each CI
run, the recorded movement trajectory of the human avatar is assessed (plotted)
and archived. We have explicitly chosen to simplify the extraction of the
human's location to acquire a ground truth in the first iterations of the
simulation. Based on the ground truth, we are able to exchange diverse
components, i.e., the semantic camera with a simulated laser scanner
\footnote{\url{openrobots.org/morse/doc/stable/user/sensors/laserscanner.html}},
to build a person hypothesis for instance, thus gradually develop, assess and
implement more complex scenarios. 

\emph{Contribution} The interactive avatar, semantic cam was extremely useful to
control, abstraction ...

\emph{Future requirements} Walking cycle, Pre-recorded activities (grasp,
loose), more than standing up, event based actions

\subsection{An Expectations Framework for Domestic Robot Assistants}
\label{scenario2}

In this scenario, an apartment is simulated in which a domestic service robot is
living together with a person. The robot is controlled via ROS and the CRAM
reactive plan language \cite{beetz2010cram}, which is used on many real robots
as well \cite{pancakes11humanoids}. The robots' duty is to observe the person
performing different activities and detect unexpected situations based on the
validation of different types of expectations \cite{Karg2013}. The detection of
such unexpected behavior can help future domestic service robots to better
assess situations and adapt their actions to human behavior. For this example,
the use of the MORSE simulator enabled us to set up a large, realistic testbed
by combining realistic robot control via the ROS middleware with the
unpredictability of human behavior using the human component of MORSE. Setting
up of such an apartment in a real-world setting would together with a suitable
sensor setup and a reliable robot control would not only introduce huge costs
but would also be a time-consuming task which can distract researchers from
their actual research focus. The use of the simulated scenario enables us to
gain many insights into the problem domain in a scenario that would not been
possible within our project and ultimately led to the successful validation of
the approach in a spatially limited real-world scenario.

\begin{figure}[H]
      \centering
      \includegraphics[width=0.9\linewidth]{morse_apartment.png}
      \caption{A simulated apartment with a domestic service robot and a person.}
      \label{fig|apartment}
\end{figure}

The human component of MORSE enabled us to test and validate our approach
dynamically in a variety of situations. Since it can be controlled in real-time
like in a 3D computer game while at the same time, a robot can be simulated by
state-of-the-art components, it is possible to generate a multitude of
situations on which the robot has to react. This greatly supported our project
to gain insights about our approach, detect weak points and make improvements.

\subsection{Data Acquisition through Automatic Scene Generation}
\label{scenario3}

Autonomous mobile robots that are to help and assist people in care homes,
households, and at other workplaces have to understand how activities performed
by humans affect the dynamics of objects in the environment. That is, they need
to know, when, where and how people manipulate objects and how they arrange and
structure them in space.

Within the STRANDS project\footnote{\url{http://www.strands-project.eu}} we are
generally aiming at understanding long-term, spatio-temporal relationships of
objects and activities of people. In the scenario described in this paper, we
looked in particular at learning qualitative spatial relations of objects on
office desks. As an accurate classification and pose estimation of objects on
real-world office desks is still a challenging and difficult task for current
robot perception systems we acquired a data set of object arrangements using
the MORSE simulator. For this, we first bootstrapped an object statistics from
manually labeled images of real office desks, and secondly, automatically
generated a set of physically possible desktop scenes (see
Figure~\ref{fig:simulated-desktop-scenes}, \cite{kunze14bootstrapping}). Based
on the generated data we learned relational models of object arrangements on
desks. The learnt models enable a robot to predict the position of an object
given a landmark. We employed these models to effectively guide a real robot in
object search tasks \cite{kunze14indirect} and evaluated its performance. The
automatic generation of object arrangements in simulation is not only useful
for the acquisition of data, but also for increasing the variability of scenes
in Human-Robot experiments in general. In future work we plan to use the
generated desktop scenes in web-applications to crowdsource Natural Language
descriptions of object arrangements and commands for robots from Internet
users.

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\columnwidth]{figs/scenes.png}
  \caption{Automatically generated scenes of office desks.}
  \label{fig:simulated-desktop-scenes}
\end{figure}

\subsection{Situation Assement for HRI and Simulated Feedback}
\label{scenario4}

When studying Human-Robot Interaction, understanding the environment in which
agents will interact is a key issue. As mentionned before, manual testing on
physical systems is labour-intensive and request expensive equipement.
In our case, the main interest is robot's situation assessment that is performed 
by our software SPARK (SPAtial Reasoning and Knowledge). MORSE gives a simulated 
environnement which is then analysed in SPARK to generate geometric and symbolic
 facts. The robot is updating its knowledge in SPARK using its own position,
human position and objects seen throught semantic cameras. The data communication 
toward SPARK is made using pocolibs middleware. The robot actions are controled 
from python using pymorse
interface\footnote{\url{http://www.openrobots.org/morse/doc/latest/pymorse.html}}.
In this particular scenario, the human is sitting in a couch and talk to the
robot to ask it to bring a specific object that may be in an other room.
To put the simulation as close as possible to reality, we simulated our testing
area which is a furnished indoor flat(Figure~\ref{fig|spark}).

\begin{figure}[H]
      \centering
      \includegraphics[width=0.9\linewidth]{morsespark.png}
      \caption{Running SPARK with MORSE}
      \label{fig|spark}
\end{figure}

Having this simulation with MORSE human helps to colaborate on a project
In the French national project MaRDi\footnote{\url{http://mardi.metz.supelec.fr}},
our partners are also using MORSE simulation to test their software and collect 
data with the same environement in there laboratory.
They can train their dialogue system using MORSE feedback to test if the robot
did the correct actions.

\subsection{Preliminary Testing of Human-Aware Navigation Planner}
\label{scenario5}

%   1- why simulation is useful/needed for your use-case
Development of human-robot interaction algorithms often require iterative
process of prototyping, testing and reviewing. Setting up and experiment and
testing of robot navigation algorithms especially for large environments
involving humans is time consuming and is subject to availability of lab
resources while working in a shared lab between different groups of
researchers. A simulation environment like Morse which implements required robot
model, PR2 robot in our case, and simulates human agents is of great help here.

%   2- is it satisfactory or not
To evaluate the improvements in the human-aware navigation planner developed at
LAAS we carried out a user study. For the user study an experiment was set up,
where a robot encounters a human crossing its path (at $90^{\circ }$ angle to
each other) while the robot is moving forward to its navigation goal. For
preliminary testing of the planning algorithm, our lab areas was simulated in
Morse as shown in figure ~\ref{fig|hanp}. This simulated environment was
extensively used to review the algorithm before it was deployed on the PR2 robot
to carry out real-world
experiments. % should include refrence to the results paper here?

\begin{figure}[H]
      \centering
      \includegraphics[width=0.9\linewidth]{morsehanp.png}
      \caption{Navigation test with MORSE}
      \label{fig|hanp}
\end{figure}

%   3- what is good and could be useful to other researcher
Full support of the PR2 robot model among others, availability of a human model,
and a convenient way of setting up experiment environment using Blender software
were the most prominent features for choosing Morse as the simulation
environment for these experiments. Since Morse already provides ROS bindings for
the PR2 robot and human pose it requires minimal effort to switch between
real-world and simulated environments.
%   4- what is missing both at the technical level (things that could be added
%      to MORSE) and at a more fundamental level (things where simulation do
%      not fit)
% technical: there is no full human posture as /tf topic for ros
%            morse as a ros-package
% fundamental: implementing human behaviors? e.g. crowd simulation

% future use of morse
As a consortium member in the EU project
SPENCER\footnote{\url{http://www.spencer.eu}}, we are interested in developing
novel algorithms for robot navigation in large populated environements,
e.g. airports. In the future we plan to use Morse to simulate such large
environment with multiple human models. This will certainly push the limits of
simulation for HRI and hopefully provide new benchmark for Morse.

\section{Discussion: Is There a Future for HRI Simulation?}


\paragraph*{The next steps}

Several noteworthy developments related to HRI are currently shaping up in the
MORSE community. We outline below some of them, that suggest new applications we
believe relevant to HRI research.

A first line of investigation relates to the procedural generation of a variety
of realistic human models. {\sc MakeHuman} is such an open-source tool that
generates anatomically, kinetically and visually realistic human models
(Figure~\ref{fig:makehuman}. This software has a tight integration with Blender,
and MORSE is soon to provide as well seamless integration with {\sc MakeHuman}
models. This would provide a wide range of characters to feed the simulations,
and extend testing environments with gender/size/age/skin color variances.  For
this feature to reach its full potential, {\sc MakeHuman} should however be
extended to support programmatic generation of models, since the graphical user
interface is currently required.

\begin{figure}[tb]
  \centering
  \includegraphics[width=.9\columnwidth]{figs/makehuman.png}
  \caption{Procedural generation of human models with {\sc MakeHuman}.}
  \label{fig:makehuman}
\end{figure}

In a related field, automatic generation of crowds and associated human
behaviours is currently worked on in the frame of the STRANDS project.
[...add more details on the expected outcomes]

Another line of investigation looks at embedding the human into the robotic
simulation. The purpose of such efforts is to provide a life-like immersive
simulation environment that would allow at the same time ecologically valid
human behaviours and repeatable, lightweight interaction settings.
In~\cite{lemaignan2012morse}, we presented how a human agent could interact with
a virtual robot through a gestual interface based on a Kinect. While arm
movements and small displacement (in a 2-3m\textsuperscript{2} zone) could be fairly
accurately transposed from the physical world to the simulation, the overall
interaction was not immersive (no head tracking, limited, non-dynamic field of
view on a TV screen, no sound). Two distinct projects are currently looking into
extending this line of research, one (at Bielefield University) aiming at
integrating emerging Virtual Reality devices (like Occulus Rift) with MORSE, the
other one (MarDI project) developing a virtual reality cave, that include 360°
projections and spatialized sound.

People like Alami also suggested that the \emph{on-line} deployment of HRI
simulations could efficiently support large scale HRI studies. The simulator and
specific interaction scenarii would be embedded in a dedicated webpage and users
would control a human avatar from their webbrowsers. This would potentially
enable collection of large behavioural datasets. While MORSE development in
that direction has yet to start, it can be noted that the Gazebo simulator
already features a limited WebGL client, that act as a proof-of-concept.

These examples and ideas hopefully give a picture of the lively landscape of the
``Simulation for HRI'' community that has built itself around the MORSE
simulator. Much remains to be imagined and achieved, and yet MORSE is already
deployed in several institutions as a platform that efficiently supports
research in human-robot interaction. As an open-source project, we strive for
new use-cases and ideas, and warmly welcome researchers that would like to join
the effort.

\section*{Acknowledgment}
TODO

\bibliographystyle{abbrv}
\bibliography{main}

\end{document}
